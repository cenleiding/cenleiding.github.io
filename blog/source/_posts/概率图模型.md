---
title: 概率图模型
date: 2018-11-09 14:58:00
tags: 概率图模型 机器学习
categories: 机器学习 概率图模型
keywords: 概率图模型
description: 十分初浅的了解一下概率图模型
image: 概率图模型/PGM_1.JPG
---



## 什么是概率图模型？

在使用**命名实体识别**时用到了LSTM+CRF模型。因此需要了解一下CRF，嗯所以顺便**简单**的了解了一下**概率图模型**。发现概率图好难，哎只能了解一下皮毛了，实在没精力去十分详细的去学习了~~

**概率图模型(Probabilistic Graphical Model,PGM),简称图模型(Graphical Model,GM),是指一种用图结构来描述多元随机变量之间条件独立关系的概率模型，从而给研究高维空间中的概率模型带来了很大的便捷性。**



> 关键：**条件独立**

概率图模型的关键在于变量之间存在的**条件独立性！** 
比如对一个K维的随机向量 X = [X1，X2……XK] 建模，假设每个变量有m个取值且都不条件独立，那么要得到这个向量的**联合概率分布**情况则需要存储$$m^K-1$$ 个参数才行，(因为每个变量的概率都与其他所有的变量有关$$p(x)=\prod_{k=1}^{K}p(x_k|x1,……，x_{k-1})$$)，这个数据量就太大了是不可能存储的。但是如果存在**条件独立**那么存储量将大大减少，比如极端情况下各个变量两两都条件独立，那么我们只需要存储m*K个参数就可以了，就有了可行性！



> 三个基本问题：表示、学习、推断

**表示问题**：对于一个概率模型，如何通过图结构来描述变量之间的依赖关系。

**学习问题**：图模型的学习包括图结构的学习和参数的学习。

**推断问题**：在已知部分变量时，计算其他变量的后验概率分布。

![img](/概率图模型/PGM_2.png)



> PGM的一些见解

机器学习的一个核心任务是从观测到的数据中挖掘隐含的知识，而概率图模型是实现这一任务的一种很elegant，principled的手段。
PGM巧妙地结合了**图论**和**概率论**。**从图论的角度**，PGM是一个图，包含结点与边。结点可以分为两类：隐含结点和观测结点。边可以是有向的或者是无向的。**从概率论的角度**，PGM是一个概率分布，图中的结点对应于随机变量，边对应于随机变量的dependency或者correlation关系。
给定一个实际问题，我们通常会观测到一些数据，并且希望能够挖掘出隐含在数据中的知识。怎么用PGM实现呢？我们构建一个图，**用观测结点表示观测到的数据，用隐含结点表示潜在的知识，用边来描述知识与数据的相互关系，最后获得一个概率分布。**给定概率分布之后，通过进行两个任务：**inference** (给定观测结点，推断隐含结点的后验分布）和**learning**(学习这个概率分布的参数），来获取知识。
PGM的强大之处在于，不管数据和知识多复杂，我们的处理手段是一样的：**建一个图，定义一个概率分布，进行inference和learning。**这对于描述复杂的实际问题，构建大型的人工智能系统来说，是非常重要的。

以上采自[谢澎涛](https://www.zhihu.com/people/xpt-cmu)

因为**图模型中的每个变量一般有着明确的解释，变量之间依赖关系一般是人工来定义。** 所以概率图模型相对于其他模型往往有着**更好解释**的优点,但是如何构建一个好的图，如何进行inference和learning很麻烦。看了很多别人用概率图模型解决问题的感想，给了我一种很麻烦而且准确度也不怎么样的感觉！相比于神经网络什么的，概率图不是一种**黑箱子**问题，他无法通过简单的调调参数就能解决问题，他更加的贴近人的正常思维，而这正是他的优势和劣势所在！



##  模型表示

![img](/概率图模型/PGM_1.jpg)

概率图模型是一类用图来表达变量相关关系的概率模型。它以图为表示工具，最常见的是用一个结点表示一个或一组随机变量，结点之间的边表示变量之间的概率相关关系，即”**变量关系图**“。

概率图模型可大致分为两类：

一. **有向无环图，称为有向图模型或贝叶斯网（Bayesian network）**

二. **无向图，称为无向图模型或马尔可夫网（Markov network）**



### 有向图模型&贝叶斯网

![img](/概率图模型/PGM_3.jpg)

**贝叶斯网(Bayesian network)**亦称“**信念网(belief network)**”，它借助**有向无环图(Directed Acyclic Graph，DAG)**来刻画属性之间的依赖关系,并使用**条件概率表(Conditional Probability Table,CPT)**来描述属性的联合概率分布。

在前面提到了，概率图模型的关键在于**条件独立性！** 而贝叶斯网结构有效地表达了属性间的条件独立性。给定父结点集πi，贝叶斯网假设每个属性与它的非后裔属性独立。$P(x1,x2...,xd) = \prod_{i=1}^{d}P(xi|\pi_i)$
则上图的联合概率分布为：$P(d,g,i,s,l) = P(d)P(i)P(g|d,i)P(s|i)P(l|g)$



#### 朴素贝叶斯分类器

**naive Bayes classifier**

一般的贝叶斯网已经很好的简化了各个属性之间的关系，充分体现了条件独立性。但是朴素贝叶斯分类器更加过分,它采用了"**属性条件独立性假设(attribute conditional independence assumption)：假设所有属性相互独立！**"嗯，所实话我觉得这货都不能算在贝叶斯网里了，因为它压根没有网络结构。。。



> 如何使用？

对于分类问题，我们经常使用**最大后验概率**来获得分类结果。

$P(c|x) = \frac{P(c)P(x|c)}{P(x)} = \frac{P(c)}{P(x)}\prod_{i=1}^{d}P(x_i|c)$       （因为互相独立，所以直接概率相乘即可。）

$h_{nb}(x) = arg_{c\in{Y}}max P(c)\prod_{i=1}^{d}P(x_i|c)$

其中，c为分类结果，x为输入值。P(x)为常量，可以忽视。

**P(c)先验概率：**可以通过样本统计获得。
$P(c) = \frac{|D_c|}{D}$ ,Dc表示训练集D中第c类样本组合成的集合。
为了避免其他属性携带的信息被训练集中未出现的属性“抹去”，常用**拉普拉斯修正(Laplacian correction)**进行**平滑(smoothing)**处理。
$P(c) = \frac{|D_c|+1}{|D|+N}$        （N为类别数）

**P(xi|c)条件概率：**也可以通过样本统计获得。
$P(x_i|c) = \frac{|D_{c,x_i}|}{|D_c|}$     （统计在同一类中属性出现的概率）
同样用拉普拉斯修正后。
$P(x_i|c) = \frac{|D_{c,x_i}|+1}{|D_c|+N_i}$  （Ni表示第i个属性可能的取值数）
另外，对于连续属性可以考虑用概率密度函数。比如可以假设$P(x_i|c) \sim N(\mu_{c,i},\sigma_{c,i}^2)$ ,μ和σ分别c类第i个属性的均值和方差，则有。
$P(x_i|c) = \frac{1}{\sqrt{2\pi}\sigma_{c,i}}exp(-\frac{(x_i-\mu_{c,i})^2}{2\sigma_{c,i}^2})$

所以朴素贝叶斯实现起来很简单，就是**对样本进行统计** 。



> 例子

比如用于文本的分类，分为脏话和非脏话。

样本：
‘你’，‘是’，‘猪’ => 1,脏话
‘你’，‘是’，'人'=>  0,非脏话

输入：
’我‘，’是‘，’猪‘

运行：
$P(1)=0.5  P(0)=0.5$
$P(我|1) =\frac{0+1}{3+1}=1/4$ $P(是|1) = \frac{1+1}{3+1} = 2/4$ $P(猪|1) = \frac{1+1}{3+1} = 2/4$
$P(我|0) =\frac{0+1}{3+1}=1/4$ $P(是|0) = \frac{1+1}{3+1} = 2/4$ $P(猪|0) = \frac{0+1}{3+1} = 1/4$
因为$P(1|'我是猪') >P(0|'我是猪') $ 所以‘我是猪’是脏话！



> 后记

 摘自西瓜书
朴素贝叶斯分类器引入 录入属性条件独立性假设，这个假设在现实应用中往往很难成立，但有趣的是，朴素贝叶斯分类器在很多情形下都能获得相当好的性能！一种解释是对分类任务来说，只需各类别的条件概率顺序正确、无须精准概率值即可导致正确分类结果。另一种解释是，若属性间依赖对所有类别影响相同或依赖关系的影响能互相抵消，则属性条件独立性假设在降低计算开销的同时不会对性能产生负面影响。



#### 半朴素贝叶斯分类器

**semi-naive Bayes classifiers**

由于时间问题不对这一部分内容深入学习，大约了解一下。
在朴素贝叶斯分类器中，进行了属性的独立性假设，虽然这大大简化了计算复杂度，但和现实任务差距有点大，所以就出现了半朴素贝叶斯分类器。他的策略是**独依赖估计(One-Dependent Estimator ODE),简单的说就是每个属性在类别之外最多仅依赖于一个其他属性**。这样的话计算不会变的太复杂，还能提高适用性

![img](/概率图模型/PGM_4.jpg)



#### 隐马尔可夫模型

这部分内容主要参考《西瓜书》和《统计学习方法》和 [刘建平Pinard](https://www.cnblogs.com/pinard/)

![img](/概率图模型/PGM_10.png)![img](/概率图模型/PGM_11.png)

**隐马尔可夫模型(Hidden Markov Model,HMM)是结构最简单的动态贝叶斯网，可以是监督的也可以是非监督的！**

##### 基础概念

**状态变量：** $ \lbrace y_1,y_2,...,y_n \rbrace ，长度n$
**状态空间：** $\lbrace s_1,s_2,...,s_N \rbrace，N个取值$
**观测变量：** $\lbrace x_1,x_2,...,x_n \rbrace$
**观测空间：** $\lbrace o_1,o_2,...,o_M \rbrace，M个取值$



> 整个网络基于**两个假设**：

**假设1：齐次马尔科夫链假设。** 即任意时刻的隐藏状态只依赖于它前一个隐藏状态。

**假设2：观测独立性假设。**即任意时刻的观察状态只仅仅依赖于当前时刻的隐藏状态。



> 整个网络基于三组参数：

● **状态转移概率** : 模型在各个状态间转换的概率，通常记为矩阵 $A=[a_{i,j}]_{N*N}$

$$a_{i,j} = P(y_{t+1} =  s_j | y_t = s_i),1\le i,j \le N$$

即表示在任意时刻t，若状态为si，则在下一时刻状态为sj的概率。

● **输出观测概率** : 模型根据当前状态获得各个观测值的概率，通常记为矩阵 $B = [b_{i,j}]_{N*M}$

$b_{i,j} = P(x_t = o_j|y_t = s_i), 1\le i\le N,1\le j \le M$

即表示在任意时刻t，若状态为si，则观测值oj被获取的概率。 

● **初始状态概率** : 模型在初始时刻各状态出现的概率，通常记为 $\pi = (\pi_1,\pi_2,...,\pi_N)$

$\pi_i = P(y_1 = s_i),1\le i \le N$

即表示模型的初始状态为si的概率。



☆  **状态空间，观测空间，三组参数$\lambda = [A,B,\pi]$ ,就能确定一个隐马尔可夫模型。**



> 三个基本问题

● **评估观察序列概率** 

即给定模型$λ=(A,B,\pi)$和观测序列$x={x_1,x_2,...x_n}$，计算在模型λ下观测序列x出现的概率$P(x|λ)$。
应用：比如已知观测序列$x_1,x_2,...,x_{n-1}$ ,来推测最有可能的$x_n$。
解决：前向后向算法

● **模型参数学习** 

即给定观测序列$x=\{ x_1,x_2,...,x_n\}$，估计模型$λ=(A,B,\pi)$的参数，使观测序列的条件概率$P(x|λ)$最大。
在这里主要针对的是非监督的HMM，因为对于监督型的HMM即状态序列已知，则只需要直接求概率即可。
解决：鲍姆-韦尔奇算法

● **预测、解码问题** 

即给定模型$λ=(A,B,\pi)$和观测序列$x={x_1,x_2,...x_n}$,求给定观测序列条件下，最可能出现的对应的状态序列。
应用：在语言识别等任务中，观测值为语音信号，隐藏状态为文字，由语音推最可能的文字。
解决：维特比算法



##### 前向后向算法

![img](/概率图模型/PGM_12.png)

用于解决**评估观察序列概率**问题。

简单来看，我们都已经得到模型$λ=(A,B,\pi)$和观测序列$x={x_1,x_2,...x_n}$，求一个概率$P(x|λ)$还不简单？
暴力求解：$P(x|λ)=\sum_{y}P(x,y|λ)=\sum_{y_1,y_2,...y_n}π_{y_1}b_{y_1}(x_1)a_{y_1,y_2}b_{y_2}(x_2)...a_{y_{n-1}y_n}b_{y_n}(x_n)$
不过不用想也知道这样肯定不行，算法复杂度：$O(nN^n)$ ，爆炸~

![img](/概率图模型/PGM_13.JPG)![img](/概率图模型/PGM_14.JPG)

**前向后向算法是前向算法和后向算法的统称，属于动态规划** 。也就是我们要通过找到局部状态递推的公式，这样一步步的从子问题的最优解拓展到整个问题的最优解。**复杂度降到了：$O(N^2*n)$** 

**前向概率：** $\alpha_i(t) = P(x_1,x_2,...x_t,q_t=i|\lambda )$ 
即第t个时刻的状态为i时，前面的观测序列为{x1,x2, ..., xt}的概率
**流程：**

1. 计算时刻1的各个隐藏状态前向概率：$α_1(i)=π_ib_i(y_1),i=1,2,...N$

2. 递推时刻2,3,...n时刻的前向概率：$α_{t+1}(i)=[\sum_{j=1}^Nα_t(j)a_{ji}]b_i(x_{t+1}),i=1,2,...N$
3. 最终结果: $P(x|λ)=\sum_{i=1}^Nα_T(i)$



**后向概率：** $ \beta_i(t) = P(x_{t+1},x_{t+2},...x_T|q_t = i,\lambda)$
当第t个时刻的状态为i时，后面的观测序列为{xt+1,xt+2, ..., xn}的概率
**流程：**

1. 初始化时刻n的各个隐藏状态后向概率：$β_T(i)=1,i=1,2,...n$
2. 递推时刻T−1,T−2,...1时刻的后向概率：$β_t(i)=\sum_{j=1}^Na_{ij}b_j(x_{t+1})β_{t+1}(j),i=1,2,...N$
3. 最终结果：$P(x|λ)=\sum_{i=1}^Nπ_ib_i(x_1)β_1(i)$



**理解：** 实际上前向后向算法作为动态规划算法，思路还是很清楚的。**每个时间点的前向概率，就是将之前时间点的情况进行了汇总，这样一来后一个时间点就可以直接处理汇总的信息，而不用像暴力方法那样从头算起~** 



**应用：**

1. 给定模型λ和观测序列x,在时刻t处于状态i的概率记为:

   $γ_t(i)=\frac{α_t(i)β_t(i)}{\sum_{j=1}^Nα_t(j)β_t(j)}$

2. 给定模型λ和观测序列x,在时刻t处于状态i，且时刻t+1处于状态j的概率记为:

   $ξ_t(i,j)=\frac{α_t(i)a_{ij}b_j(x_{t+1})β_{t+1}(j)}{\sum_{r=1}^N\sum_{s=1}^Nα_t(r)α_{rs}b_s(x_{t+1})β_{t+1}(s)}$

3. 将$γt(i)和ξt(i,j)$在各个时刻tt求和，可以得到：

   ●在观测序列x下状态i出现的期望值$\sum_{t=1}^nγ_t(i)$

   ●在观测序列x下由状态i转移的期望值$\sum_{t=1}^{n−1}γ_t(i)$

   ●在观测序列x下由状态i转移到状态j的期望值$\sum_{t=1}^{n−1}ξ_t(i,j)$




##### 鲍姆-韦尔奇算法

鲍姆-韦尔奇算法的目的是**进行参数学习**。 

实际上，HMM有两种情况：一种是**监督的**即隐藏状态已标注，比如由英文=>中文，可以获得标注语料。另一种是**非监督的**即隐藏状态未标注，比如对于语音是很难标注的因为是连续的。



>  **对于监督型的HMM：** 我们可以用**最大似然**来求解参数。

假设样本从隐藏状态i转移到j的频率计数是Aij,那么状态转移矩阵求得为：

**状态转移矩阵： **$A=[a_{ij}],其中a_{ij}=\frac{A_{ij}}{\sum_{s=1}^NA_{is}}$

假设样本隐藏状态为j且观测状态为k的频率计数是Bjk,那么观测状态概率矩阵为：

**观测状态概率矩阵 : ** $B=[b_j(k)],其中b_j(k)=\frac{B_{jk}}{\sum_{s=1}^MB_{js}}$

假设所有样本中初始隐藏状态为i的频率计数为C(i),那么初始概率分布为：

**初始概率分布：** $\Pi=\pi(i)=\frac{C(i)}{\sum_{s=1}^NC(s)}$



> **对于非监督型的HMM**：我们需要用**鲍姆-韦尔奇算法**

实际上**鲍姆-韦尔奇算法就是EM算法**，两者的原理是一样的，只是换了一个马甲而已。。
所以我们需要不断的循环互求**隐藏状态**和**模型参数** 。

**流程：**

1. 随机初始化所有的$\pi_i,a_{ij},b_j(k)$

2. 对于每个样本d=1,2,...D,用前向后向算法计算$γ_t^{(d)}(i)，ξ_t^{(d)}(i,j),t=1,2...n$,也就是求了隐藏值。

3. 更新模型参数：

  $\pi_i=\frac{\sum_{d=1}^Dγ_t^{(d)}(i)}{D}$

  $a_{ij}=\frac{\sum_{d=1}^D\sum_{t=1}^{T−1}ξ_t^{(d)}(i,j)}{\sum_{d=1}^D\sum_{t=1}^{T−1}γ_t^{(d)}(i)}$

  $b_j(k)=\frac{\sum_{d=1}^D\sum_{t=1,o_t^{(d)}=v_k}^Tγ_t^{(d)}(i)}{\sum_{d=1}^D\sum_{t=1}^Tγ_t^{(d)}(i)}$

4. 如果$π_i,a_{ij},b_j(k)$的值已经收敛，则算法结束，否则回到第2步继续迭代。




##### 维特比算法

![img](/概率图模型/PGM_15.GIF)

**维特比算法Viterbi algorithm**是一个通用的**求序列最短路径的动态规划算法**，经常用于**解码问题**，比如在CRF中。既然是动态规划算法，那么就需要找到合适的局部状态，以及局部状态的递推公式。

**流程：**
输入：HMM模型λ=(A,B,Π)，观测序列O=(o1,o2,...oT)
输出：最有可能的隐藏状态序列$I^∗={i^∗1,i^∗2,...i^∗T}$

1. 初始化局部状态：

   $δ_1(i) = \pi_ib_i(o_1),i=1,2...N$

   $\psi_1(i)=0,i=1,2...N$

2. 进行动态规划递推时刻t=2,3,...T时刻的局部状态：

  $δ_t(i)=max_{1≤j≤N}[δ_{t−1}(j)a_{ji}]b_i(O_t),i=1,2...N$

  $\psi_t(i)=argmax_{1≤j≤N}[δ_{t−1}(j)a_{ji}],i=1,2...N$

3. 计算时刻T最大的δT(i),即为最可能隐藏状态序列出现的概率。时刻T最大的Ψt(i),即为时刻T最可能的隐藏状态。

   $P∗=max_{1≤j≤N}δ_T(i)$

   $i^∗_T=argmax_{1≤j≤N}[δ_T(i)]$

4. 利用局部状态Ψ(i)开始回溯。对于t=T−1,T−2,...,1t=T−1,T−2,...,1：

   $i^∗_t=\psi_{t+1}(i^∗_{t+1})$


终得到**最有可能的隐藏状态序列** $I^∗={i^∗_1,i^∗_2,...i^∗_T}$



**理解：** 同作为动态规划，维特比算法和前向后向算法，思路一致。区别在于**前向后向算法每个时间每个状态保存的是概率的总和，而维特比算法则保存的是最大的概率值和路径。** 因为前向后向算法需要的是一个状态出现的期望，而维特比则是需要一个状态出现的最大概率！



## 模型学习

模型学习一般可分为参数学习(估计)和结构学习。
结构学习一般比较困难，**一般由领域专家来构建**，这里只是简单了解一下。
参数学习**在无隐变量的情况下，直接用极大似然或最大后验。存在隐变量的情况下，则需要EM算法等**。
另外，如果将参数也看作待推测的变量，那么**参数估计也可以看作推断！**



### 参数学习

#### 极大似然与最大后验

> 极大似然估计 Maximum Likelihood Estimate
>
> 最大后验概率估计 Maximum A Posteriori estimation

在看概率图模型时，经常会看到最大似然估计和最大后验估计。因为概率论的东西基本全还给老师了，所以看的一愣一愣的。没办法只好查资料补起来，说实话这两个东西初看看挺简单的，以为已经理解了，但是当我尝试去分析一个问题时又会有点茫然。。真是头大，到写这些东西，我仍觉得并没有真正理解这两个概念。。。。。



##### 起源

**极大似然估计（MLE）--  频率学派**

**最大后验概率估计（MAP）-- 贝叶斯派**

事实上，我对这两个学派并没有什么兴趣。他们只是根据自己的理解分别提出了各自的观点而已。

频率派认为**参数是个客观存在的固定值**，而贝叶斯派则认为**参数是服从一个分布的随机值**。

相比于频率派贝叶斯派增加了**参数的先验分布**，然后根据数据计算**参数的后验分布** 。这个先验分布**一般根据历史数据统计得到，也可以人为经验给定**，这使的结果并不完全依赖于样本数据，**于是往往用后验估计更加可靠。**但问题在于怎么获得这个先验假设？好的先验假设确实有用，但拍拍脑袋想出来的先验假设就只能呵呵了~

另外，**这两个学派至今未能达成共识！** 想起自己刚看这两个估计时傻傻的想把他们合在一起理解真是头大。。

另外，**贝叶斯决策论**指的就是取后验概率最大时的参数。



##### 用途

两者的用途一致：**对参数进行估计！**

即**模型已定，参数未知** 。



##### 极大似然估计MLE

$P(样本D|参数\theta)$

**核心目标：找到参数θ的一个估计值，使得当前样本出现的可能性最大。**

假设有一个样本集合D，且这些样本都是独立的，则参数θ对于数据集D的似然为：

$$P(D|\theta) = P(x1,x2…xn|\theta) = \prod_{x\in{D}}P(x|\theta)$$

由于实际使用中，P(x|θ)往往比较小，连乘容易造成**浮点运算下溢**，而且为了**求导方便**，通常使用**对数似然(log-likelihood):**

$LL(\theta) = log P(D|\theta) = \sum_{x\in{D}} log P(x|\theta)$

此时，参数θ的**极大似然估计**为：

$\hat\theta = arg_{\theta}maxLL(\theta)$

而这个最大值可以通过**求导得出** 。



> 例子

以最为简单的投硬币为例，现在有一个硬币，如果正面朝上记为1，反面朝上记为0，抛10次的结果如下：1111100011=>7正3反。我们的目标就是求出硬币向上的概率。

首先这个问题有10个样本，模型则是二项分布，参数为向上概率θ。

对于每个样本有：$P(x|\theta) = \theta^{x}*(1-\theta)^{1-x}$

那么对于整个数据有似然函数：$P(X|\theta) = \theta^{7}*(1-\theta)^{3}$

最后转为对数似然并求导，令导数为0，可以得到θ=0.7。与我们的预期一致。

**极大似然估计的问题：** 可以看出通过极大似然估计得到的结果**严重依赖于样本**，正面向上的概率为0.7与我们的日常经验不符，这就是极大似然的问题所在。



#####　最大后验概率估计（MAP）

极大似然估计的问题就是太依赖样本了，于是最大后验概率估计添加了一项**先验概率**，可以将其看成**惩罚**，来平衡由样本得到的概率。

$P(参数\theta|样本D)$

最大后验求的是在样本下，参数θ的最大值。嗯，并不能直观的理解。使用**贝叶斯公式**转换看看。

**贝叶斯公式：** $P(x|y) = \frac{P(y|x)P(x)}{P(y)}$

转换后：$P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}$

P(D|θ)：似然概率，P(θ)：先验概率，P(D)：能用全概率公式计算，但不需要，因为我们只关心使值最大的θ，而不是值的本身。

于是求最大后验概率估计变的和求极大似然估计差不多了，就是多了一个先验概率。

> 例子

任然是刚才的投硬币，我们发现0.7并不符合常识。所以我们加一个**先验概率：硬币是正常的,向上的概率符合最大值取在0.5处的Beta分布。** 这样再求最大值，θ就会处于0.5~0.7，被修正了。



##### 两者的关系

很明显，**最大后验可以认为是极大似然通过先验分布进行了修正。**

特别的，**可以将极大似然看成先验为均匀分布的最大后验！**

特别的，**当样本数十分大时，先验概率将几乎没有影响，极大似然的结果与最大后验一致**



#### EM算法

**EM(Expectation-Maximization)**是常用的**估计参数隐变量**的利器，是一种**迭代式**的方法，其基本思想是：**若参数Θ已知，则可根据训练数据推断出最优隐变量Z的值(E步)；反之，若Z值已知，则可以方便地对参数Θ做极大似然估计(M步)。**

在这里只是最最基础的了解，我并不想知道他的推导证明，只想知道他具体是怎么运行的在干什么~感谢文章[What is the expectation maximization algorithm?](https://www.nature.com/articles/nbt1406)提供的例子！

![img](/概率图模型/PGM_5.png)

仍然是最常见的投币问题，仍然是估计硬币向上概率。
现在有两枚硬币，我们有其投币后的结果，在一般情况下，我们只要分别计算一下他们各自的最大似然估计就行了，如图a所示。但现在问题来了：如果我们不知道每一次投的是哪一个硬币，即对于每一个样本其“硬币种类”属性是未知的，是**隐变量**。这个时候我们该怎么求两枚硬币各自的“向上概率”这个**参数**？ 
这个隐变量的存在使得问题变得很麻烦，但是EM算法却十分巧妙的解决了这个问题！

● **E步(Expectation):基于参数Θ推断隐变量Z的期望。**

在这个例子中，我们可以先假设一个Θ。如$\theta_A = 0.6,\theta_B = 0.5$,于是我们可以用这个假设的参数去**推断隐变量的期望**。 
比如对于第一个样本，5正5负，如果是A，其出现概率为$0.6^5*0.4^5$;如果是B，其出现的概率为$0.5^{10}$ 。则期望为：$\frac{0.6^5*0.4^5}{0.5^{10}} \approx \frac{0.45}{0.55}$ 及0.45的可能为A，0.55的可能为B。

● **M步(Maximization):基于观测变量和隐变量的期望Z，对参数Θ做最大似然估计**

在E步我们已经获得了隐变量的期望，那么问题就又变的简单了，对参数求最大似然估计即可。如上图所示，我们得到了新的参数$\theta_A\approx0.71,\theta_B\approx0.58$ 

● **EM循环至收敛**

接下来要做的就是不断的重复E和M，在数学上可以证明最终会收敛到局部最优解。



> 其他

还可以将EM算法看作用**坐标下降(coordinate descent)法**来最大化对数似然下界的过程。

![img](/概率图模型/PGM_6.png)

另外，EM算法的思想和**以前Google的PageRank**的思想可以说十分相似，都是一开始给一个初始值，然后通过不断的自我修正来接近实际值。在PageRank中，网页的**得分**是根据**网页连入量**和**连入网页质量**决定的,也就是说一个网站被别的网站连的越多，且这些网站得分越高，那么这个网站的得分也就越高。但是有个问题，我们并不知道网站的初始得分，且网站得分是由其他网站得分求出的，这就陷入了**自己求自己**的尴尬问题。和EM算法思想一样，先给所有网站附一个一样的得分，然后不断的用现有得分更新得分，最终获得一个稳定的得分。



## 模型推断

**推断(inference)** 是指在观测到部分变量$e={e_1,e_2...e_m}$时，计算其他变量的每个子集$q = {q_1,q_2...q_n}$的后验概率$p(q|e)$ 。设z为其余变量。
根据条件概率定义：$p(q|e) =\frac{p(q,e)}{p(e)}=\frac{\sum_zp(q,e,z)}{\sum_{q,z}p(q,e,z)} $ 。
可以看出，推断问题的**关键**就是**如何高效地计算边际概率分布！**

概率图模型的推断可以分为两类：**精确推断**和**近似推断**



### 精确推断

精确推断希望计算出目标变量的边际分布或条件分布的精确值，但由于计算复杂度随着极大团规模的增长呈指数增长，所以**适用范围有限。**

精确推断实质是**动态规划算法**，它利用条件独立性来消减计算量。



#### 变量消去

变量消去是最为直观的精确推断算法。

借用西瓜书中的例子：

![img](/概率图模型/PGM_7.png)

比如我们目标要求边际概率$p(x_5)$

则  $\begin{eqnarray*}P(x_5) &=& \sum_{x_4}\sum_{x_3}\sum_{x_2}\sum_{x_1}P(x_1,x_2,x_3,x_4,x_5)\\&=&\sum_{x_4}\sum_{x_3}\sum_{x_2}\sum_{x_1}P(x_1)P(x_2|x_1)P(x_3|x_2)P(x_4|x_3)P(x_5|x_3)\end{eqnarray*}$

可以看出计算次数为5x1x2x3x4x5。其主要问题是：**许多项进行了重复的计算**！
那么变量消去的目的就在于**避免这种重复计算** 。
进行简单的分配可以得到：

$\begin{eqnarray*}P(x_5) &=& \sum_{x_3}P(x_5|x_3)\sum_{x_4}P(x_4|x_3)\sum_{x_2}P(x_3|x_2)\sum_{x_1}P(x_1)P(x_2|x1)\\ &=& \sum_{x_3}P(x_5|x_3)\sum_{x_4}P(x_4|x_3)\sum_{x_2}P(x_3|x_2)m_{12}(x_2)\\ &...&\\&=&m_{35}(x_5)    \end{eqnarray*}$

这个过程可以看成**从图的边缘向目标节点出发，逐步求各个节点的边际概率，直到求出目标节点边际概率。**

但是单纯的变量消去仍有一个**问题：当我们分别求不同节点的边际概率时，需要从头再计算一遍，无疑这又重复计算了。** 而**信念传播**就是用来解决这个问题。



#### 信念传播

**信念传播(Belief Propagation)算法将变量消去中的求和操作看作一个消息传递过程。** 

![img](/概率图模型/PGM_8.png)

在信念传播算法中，**一个节点仅在接收到来自其他所有结点的消息后才能向另一个节点发送消息，且结点的边际分布正比于它所接收的信息的乘积。**

这么一来，问题就简单了，对于无环图，信念传播算法经过两个步骤即可完成：

● 指定一个根节点，从所有叶节点开始向根节点传递消息，直到根节点收到所有邻结点的消息。

● 从根结点开始向叶结点传递消息，直到所有叶节点均收到消息。

这样就可以**获得所有变量的边际概率** ，而不需要多次计算！



### 近似推断

精确推断的开销还是太大了，因此现实中一般使用近似推断方法。

近似推断可以分为两类：**一.采样sampling，通过使用随机化方法完成近似。**

​                                          **二.使用确定性近似完成近似推断，比如变分推断。**

嗯，这部分内容难度有点大，而且我也只是出于了解的目的，所以只写最直观的感受~



#### 基于采样的近似推理

举个简单的例子：给定一个硬币，你如何确定它被抛出后正面朝上的概率？最简单的做法就是抛这个硬币，比如抛 100 次，然后看其中正面朝上多少次。

这是一种用于估计正面朝上的概率的基于采样的算法。对于概率图模型领域内的更复杂的算法，你也可以使用类似的流程。基于采样的算法还可以进一步分为两类。一类中的**样本是相互独立**，比如上面抛硬币的例子。这些算法被称为**蒙特卡洛方法**。

对于有很多变量的问题，生成高质量的独立样本是很困难的，因此我们就生成带有依赖关系的样本，也就是说**每个新样本都是随机的，但邻近上一个样本** 。这种算法被称为**马尔可夫链蒙特卡洛（MCMC）方法** ，因为这些样本会形成一个马尔可夫链（Markov chain）。

要详细理解什么是**蒙特卡洛**，什么是**马尔科夫蒙特卡洛MCMC**，什么是**M-H算法**，什么是**Gibbs采样**，可以看一下[Eureka](https://www.zhihu.com/people/eureka-42-21)的知乎笔记，其内还有对应的Python实现，还是极好的。



#### 变分法近似推理

变分法近似推理不是使用采样，而是试图通过分析的方式来近似所需的分布。假设你写出了计算相关分布的表达式——不管这个分布是边际概率分布还是后验概率分布。

通常这些表达式里面有求和或积分，要精确评估是极其消耗计算资源的。要近似这些表达式，一种好方法是求解一个替代表达式，并且通过某种方法使该替代表达式接近原来的表达式。这就是变分法背后的基本思想。

![img](/概率图模型/PGM_9.JPG)

例如：黄色的分布是我们的原始目标p，不好求。它看上去有点像高斯，那我们尝试从高斯分布中找一个红q和一个绿q，分别计算一下p和他们重叠部分面积，选更像p的q作为p的近似分布。这样就从“求分布”的推断问题，变成了“缩小距离”的优化问题。

